{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Implement the two layer network for m-samples, n-features as we discussed in class (both FP and BP) and for N layers in the hidden layer. Split the data (you can use the log. reg. data or any other one) and train your network with 80% of the data. Test your network with the test data. Report the evaluation metrics for varying number of layers in the network. Also evaluate one more activation function (ReLU/tanh) other than sigmoid function.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_sigmoid(z):\n",
    "    return 1/(1+np.e**(-z))\n",
    "def activation_tanh(z):\n",
    "    return np.tanh(z)\n",
    "def sigmoid_der(data):\n",
    "    return data*(1-data)\n",
    "def tanh_der(z):\n",
    "    return (1-np.tanh(z)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "data_ls = pd.read_csv(\"Logistic_regression_ls.csv\",index_col=False)\n",
    "X = data_ls.T.iloc[:2].T.to_numpy()\n",
    "y = data_ls.T.iloc[-1:].T.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(np.shape(X_train),np.shape(y_train))\n",
    "N = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am creating a Neural Network with 1 hidden layer, 1 output layer with m samples features, n features in hidden layer and N neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardPropogation(X_train, weight_1, weight_2, B_1, B_2, activation):\n",
    "    m1, n1 = np.shape(X_train)\n",
    "    N = np.shape(weight_2)[1]\n",
    "\n",
    "    Z_1 = weight_1@X_train.T\n",
    "    Z_1 = Z_1 + B_1\n",
    "    A_1 = activation(Z_1)\n",
    "\n",
    "    n2, m2 = np.shape(A_1)\n",
    "    Z_2 = weight_2@A_1\n",
    "    Z_2 = Z_2 + B_2\n",
    "    A_2 = activation(Z_2)\n",
    "    \n",
    "    return {\n",
    "        'A_1':A_1,\n",
    "        'A_2':A_2,\n",
    "        'B_1':B_1,\n",
    "        'B_2':B_2,\n",
    "        'weight_1':weight_1,\n",
    "        'weight_2':weight_2,\n",
    "        'Z_1':Z_1,\n",
    "        'Z_2':Z_2\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackwardPropogation(X_train, y_train, data, act_der):\n",
    "    m1, n1 = np.shape(X_train)\n",
    "\n",
    "    dZ_2 = data['A_2'] - y_train.T\n",
    "    dW_2 = (dZ_2 @ data['A_1'].T)/m1\n",
    "    dB_2 = 1/m1*np.sum(dZ_2,axis=1,keepdims=True)\n",
    "\n",
    "    dZ_1 = (data['weight_2'].T@dZ_2)*((act_der(data['A_1'])))\n",
    "    dW_1 = 1/m1*(dZ_1@X_train)\n",
    "    dB_1 = 1/m1*np.sum(dZ_1,axis=1,keepdims=True)\n",
    "    \n",
    "    return dW_1, dW_2, dB_1, dB_2, dZ_1, dZ_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = np.shape(X_train)\n",
    "weight_1 = np.random.rand(N*n).reshape(N,n)\n",
    "weight_2 = np.random.rand(N).reshape(1,N)\n",
    "B_1 = np.ones((N,1))\n",
    "B_2 = np.ones((1,1))\n",
    "\n",
    "i = 0\n",
    "while i<20000:\n",
    "    data = ForwardPropogation(X_train, weight_1, weight_2, B_1, B_2, activation_sigmoid)\n",
    "    data_back = BackwardPropogation(X_train,y_train,data, sigmoid_der)\n",
    "    weight_1 = weight_1 - 0.1*data_back[0]\n",
    "    weight_2 = weight_2 - 0.1*data_back[1]\n",
    "    B_1 = B_1 - 0.1*data_back[2]\n",
    "    B_2 = B_2 - 0.1*data_back[3]\n",
    "    \n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 1:[[0.76071111 0.59090638]\n",
      " [1.30604321 0.6626462 ]\n",
      " [1.14937657 1.18596708]\n",
      " [0.62583658 0.47134062]\n",
      " [0.90643133 1.22788965]\n",
      " [0.67208391 0.5389203 ]\n",
      " [0.68286311 0.54287403]\n",
      " [0.25590349 0.06776256]\n",
      " [0.48607737 0.42774783]\n",
      " [1.08086751 1.00891058]],\n",
      "Weight 2:[[ 6.00241476 -2.17876747 -2.57810504 -0.72135595 -2.57480347  5.28785034\n",
      "   5.35432514  0.79492281  3.85173045 -1.81357335]]\n"
     ]
    }
   ],
   "source": [
    "m, n = np.shape(X_test)\n",
    "print(f\"Weight 1:{weight_1},\\nWeight 2:{weight_2}\")\n",
    "predicted = ForwardPropogation(X_test, weight_1, weight_2, B_1[:,:m], B_2[:,:m], activation_sigmoid)\n",
    "predicted[\"A_2\"] = np.round(predicted[\"A_2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 1.0\n",
      "Accuracy 1.0\n",
      "Recall 1.0\n",
      "F1 Score 1.0\n"
     ]
    }
   ],
   "source": [
    "Accuracy = accuracy_score(y_test.T, predicted[\"A_2\"])\n",
    "Precision = precision_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "Recall = recall_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "F1 = f1_score(y_test.T,predicted[\"A_2\"],average=\"micro\")\n",
    "print(f\"Precision {Precision}\")\n",
    "print(f\"Accuracy {Accuracy}\")\n",
    "print(f\"Recall {Recall}\")\n",
    "print(f\"F1 Score {F1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 1:[[0.81048469 0.66754128]\n",
      " [0.96331099 1.05910533]\n",
      " [1.15520884 0.98870695]\n",
      " [1.01730904 0.80090507]\n",
      " [1.00124069 0.95913878]],\n",
      "Weight 2:[[ 6.96079343 -2.04696047 -2.40197977  9.08411996 -2.02898819]]\n",
      "Precision 1.0\n",
      "Accuracy 1.0\n",
      "Recall 1.0\n",
      "F1 Score 1.0\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "m, n = np.shape(X_train)\n",
    "weight_1 = np.random.rand(N*n).reshape(N,n)\n",
    "weight_2 = np.random.rand(N).reshape(1,N)\n",
    "B_1 = np.ones((N,1))\n",
    "B_2 = np.ones((1,1))\n",
    "\n",
    "m, n = np.shape(X_train)\n",
    "weight_1 = np.random.rand(N*n).reshape(N,n)\n",
    "weight_2 = np.random.rand(N).reshape(1,N)\n",
    "B_1 = np.ones((N,1))\n",
    "B_2 = np.ones((1,1))\n",
    "\n",
    "i = 0\n",
    "while i<20000:\n",
    "    data = ForwardPropogation(X_train, weight_1, weight_2, B_1, B_2, activation_sigmoid)\n",
    "    data_back = BackwardPropogation(X_train,y_train,data, sigmoid_der)\n",
    "    weight_1 = weight_1 - 0.1*data_back[0]\n",
    "    weight_2 = weight_2 - 0.1*data_back[1]\n",
    "    B_1 = B_1 - 0.1*data_back[2]\n",
    "    B_2 = B_2 - 0.1*data_back[3]\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "m, n = np.shape(X_test)\n",
    "print(f\"Weight 1:{weight_1},\\nWeight 2:{weight_2}\")\n",
    "predicted = ForwardPropogation(X_test, weight_1, weight_2, B_1[:,:m], B_2[:,:m], activation_sigmoid)\n",
    "predicted[\"A_2\"] = np.round(predicted[\"A_2\"])\n",
    "\n",
    "Accuracy = accuracy_score(y_test.T, predicted[\"A_2\"])\n",
    "Precision = precision_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "Recall = recall_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "F1 = f1_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "\n",
    "print(f\"Precision {Precision}\")\n",
    "print(f\"Accuracy {Accuracy}\")\n",
    "print(f\"Recall {Recall}\")\n",
    "print(f\"F1 Score {F1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 1:[[ 2.54945359  1.33747571]\n",
      " [-0.59524821 -0.86574389]\n",
      " [-0.10227785 -0.06352432]\n",
      " [ 8.25518089  6.18319007]\n",
      " [-1.14831459 -0.17557813]],\n",
      "Weight 2:[[ 0.20005603 -1.72751028  1.18769681  0.7900826  -1.27464463]]\n",
      "Precision 0.9787234042553191\n",
      "Accuracy 0.0\n",
      "Recall 1.0\n",
      "F1 Score 1.0\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "m, n = np.shape(X_train)\n",
    "weight_1 = np.random.rand(N*n).reshape(N,n)\n",
    "weight_2 = np.random.rand(N).reshape(1,N)\n",
    "B_1 = np.ones((N,1))\n",
    "B_2 = np.ones((1,1))\n",
    "\n",
    "data = ForwardPropogation(X_train, weight_1, weight_2, B_1, B_2, activation_tanh)\n",
    "data_back = BackwardPropogation(X_train,y_train,data, tanh_der)\n",
    "i = 0\n",
    "while i<100000:\n",
    "    \n",
    "    weight_1 = weight_1 - 0.1*data_back[0]\n",
    "    weight_2 = weight_2 - 0.1*data_back[1]\n",
    "    B_1 = B_1 - 0.1*data_back[2]\n",
    "    B_2 = B_2 - 0.1*data_back[3]\n",
    "    data = ForwardPropogation(X_train, weight_1, weight_2, B_1, B_2, activation_tanh)\n",
    "    data_back = BackwardPropogation(X_train,y_train,data, tanh_der)\n",
    "    i+=1\n",
    "m, n = np.shape(X_test)\n",
    "print(f\"Weight 1:{weight_1},\\nWeight 2:{weight_2}\")\n",
    "predicted = ForwardPropogation(X_test, weight_1, weight_2, B_1[:,:m], B_2[:,:m], activation_tanh)\n",
    "predicted[\"A_2\"] = np.round(predicted[\"A_2\"])\n",
    "Accuracy = accuracy_score(y_test.T, predicted[\"A_2\"])\n",
    "Precision = precision_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "Recall = recall_score(y_test.T, predicted[\"A_2\"], average=\"micro\")\n",
    "print(f\"Precision {Precision}\")\n",
    "print(f\"Accuracy {Accuracy}\")\n",
    "print(f\"Recall {Recall}\")\n",
    "print(f\"F1 Score {F1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
